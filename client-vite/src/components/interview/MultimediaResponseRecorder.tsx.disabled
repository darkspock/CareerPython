import React, { useState, useRef, useEffect } from 'react';

interface MultimediaResponseRecorderProps {
  questionId: string;
  allowedTypes: ('audio' | 'video' | 'image' | 'file')[];
  onResponseChange: (response: MultimediaResponse) => void;
  disabled?: boolean;
  maxDuration?: number; // in seconds
  maxFileSize?: number; // in bytes
}

interface MultimediaResponse {
  type: 'audio' | 'video' | 'image' | 'file';
  data: Blob | File | null;
  metadata: {
    duration?: number;
    size: number;
    format: string;
    timestamp: Date;
    deviceInfo?: {
      userAgent: string;
      mediaDevices?: MediaDeviceInfo[];
    };
  };
}

interface RecordingState {
  isRecording: boolean;
  isPaused: boolean;
  duration: number;
  currentTime: number;
}

const MultimediaResponseRecorder: React.FC<MultimediaResponseRecorderProps> = ({
  questionId,
  allowedTypes,
  onResponseChange,
  disabled = false,
  maxDuration = 300, // 5 minutes default
  maxFileSize = 50 * 1024 * 1024 // 50MB default
}) => {
  const [activeType, setActiveType] = useState<'audio' | 'video' | 'image' | 'file' | null>(null);
  const [recordingState, setRecordingState] = useState<RecordingState>({
    isRecording: false,
    isPaused: false,
    duration: 0,
    currentTime: 0
  });
  const [mediaStream, setMediaStream] = useState<MediaStream | null>(null);
  const [recordedBlob, setRecordedBlob] = useState<Blob | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [availableDevices, setAvailableDevices] = useState<MediaDeviceInfo[]>([]);
  const [selectedCamera, setSelectedCamera] = useState<string>('');
  const [selectedMicrophone, setSelectedMicrophone] = useState<string>('');

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const audioRef = useRef<HTMLAudioElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const recordingTimerRef = useRef<NodeJS.Timeout | null>(null);
  const chunksRef = useRef<Blob[]>([]);

  useEffect(() => {
    loadAvailableDevices();
    return cleanup;
  }, []);

  useEffect(() => {
    if (recordingState.isRecording && !recordingState.isPaused) {
      recordingTimerRef.current = setInterval(() => {
        setRecordingState(prev => ({
          ...prev,
          currentTime: prev.currentTime + 1
        }));
      }, 1000);
    } else {
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
      }
    }

    return () => {
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
      }
    };
  }, [recordingState.isRecording, recordingState.isPaused]);

  const loadAvailableDevices = async () => {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      setAvailableDevices(devices);

      // Set default devices
      const videoDevice = devices.find(d => d.kind === 'videoinput');
      const audioDevice = devices.find(d => d.kind === 'audioinput');

      if (videoDevice) setSelectedCamera(videoDevice.deviceId);
      if (audioDevice) setSelectedMicrophone(audioDevice.deviceId);
    } catch (err) {
      console.error('Failed to enumerate devices:', err);
    }
  };

  const startRecording = async (type: 'audio' | 'video') => {
    try {
      setError(null);
      setRecordedBlob(null);

      const constraints: MediaStreamConstraints = {
        audio: selectedMicrophone ? { deviceId: selectedMicrophone } : true,
        video: type === 'video' && selectedCamera ? { deviceId: selectedCamera } : type === 'video'
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      setMediaStream(stream);

      if (videoRef.current && type === 'video') {
        videoRef.current.srcObject = stream;
        videoRef.current.play();
      }

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: type === 'video' ? 'video/webm;codecs=vp9' : 'audio/webm;codecs=opus'
      });

      chunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(chunksRef.current, {
          type: type === 'video' ? 'video/webm' : 'audio/webm'
        });
        setRecordedBlob(blob);

        const response: MultimediaResponse = {
          type,
          data: blob,
          metadata: {
            duration: recordingState.currentTime,
            size: blob.size,
            format: type === 'video' ? 'webm' : 'webm',
            timestamp: new Date(),
            deviceInfo: {
              userAgent: navigator.userAgent,
              mediaDevices: availableDevices
            }
          }
        };

        onResponseChange(response);
        cleanup();
      };

      mediaRecorderRef.current = mediaRecorder;
      mediaRecorder.start(1000); // Collect data every second

      setRecordingState({
        isRecording: true,
        isPaused: false,
        duration: 0,
        currentTime: 0
      });

      setActiveType(type);

    } catch (err: any) {
      setError(`Failed to start recording: ${err.message}`);
      console.error('Recording error:', err);
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && recordingState.isRecording) {
      mediaRecorderRef.current.stop();
      setRecordingState(prev => ({
        ...prev,
        isRecording: false,
        duration: prev.currentTime
      }));
    }
  };

  const pauseRecording = () => {
    if (mediaRecorderRef.current && recordingState.isRecording) {
      if (recordingState.isPaused) {
        mediaRecorderRef.current.resume();
        setRecordingState(prev => ({ ...prev, isPaused: false }));
      } else {
        mediaRecorderRef.current.pause();
        setRecordingState(prev => ({ ...prev, isPaused: true }));
      }
    }
  };

  const captureImage = async () => {
    try {
      setError(null);

      const constraints: MediaStreamConstraints = {
        video: selectedCamera ? { deviceId: selectedCamera } : true
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      setMediaStream(stream);

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        await videoRef.current.play();

        // Wait a moment for the video to stabilize
        setTimeout(() => {
          captureFromVideo();
        }, 1000);
      }

      setActiveType('image');
    } catch (err: any) {
      setError(`Failed to access camera: ${err.message}`);
    }
  };

  const captureFromVideo = () => {
    if (videoRef.current && canvasRef.current) {
      const canvas = canvasRef.current;
      const video = videoRef.current;
      const ctx = canvas.getContext('2d');

      if (ctx) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);

        canvas.toBlob((blob) => {
          if (blob) {
            setRecordedBlob(blob);

            const response: MultimediaResponse = {
              type: 'image',
              data: blob,
              metadata: {
                size: blob.size,
                format: 'png',
                timestamp: new Date(),
                deviceInfo: {
                  userAgent: navigator.userAgent,
                  mediaDevices: availableDevices
                }
              }
            };

            onResponseChange(response);
          }
          cleanup();
        }, 'image/png');
      }
    }
  };

  const handleFileUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    if (file.size > maxFileSize) {
      setError(`File size exceeds maximum allowed size of ${Math.round(maxFileSize / 1024 / 1024)}MB`);
      return;
    }

    setError(null);
    setRecordedBlob(file);

    const response: MultimediaResponse = {
      type: 'file',
      data: file,
      metadata: {
        size: file.size,
        format: file.type || 'unknown',
        timestamp: new Date()
      }
    };

    onResponseChange(response);
    setActiveType('file');
  };

  const playRecording = () => {
    if (recordedBlob && activeType) {
      const url = URL.createObjectURL(recordedBlob);

      if (activeType === 'audio') {
        if (audioRef.current) {
          audioRef.current.src = url;
          audioRef.current.play();
          setIsPlaying(true);

          audioRef.current.onended = () => {
            setIsPlaying(false);
            URL.revokeObjectURL(url);
          };
        }
      } else if (activeType === 'video') {
        if (videoRef.current) {
          videoRef.current.srcObject = null;
          videoRef.current.src = url;
          videoRef.current.play();
          setIsPlaying(true);

          videoRef.current.onended = () => {
            setIsPlaying(false);
            URL.revokeObjectURL(url);
          };
        }
      }
    }
  };

  const deleteRecording = () => {
    setRecordedBlob(null);
    setActiveType(null);
    setError(null);
    onResponseChange({
      type: 'audio',
      data: null,
      metadata: {
        size: 0,
        format: '',
        timestamp: new Date()
      }
    });
  };

  const cleanup = () => {
    if (mediaStream) {
      mediaStream.getTracks().forEach(track => track.stop());
      setMediaStream(null);
    }

    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }

    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current);
    }
  };

  const formatTime = (seconds: number): string => {
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = seconds % 60;
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
  };

  const formatFileSize = (bytes: number): string => {
    if (bytes === 0) return '0 B';
    const k = 1024;
    const sizes = ['B', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
  };

  return (
    <div className="space-y-4">
      {/* Type Selection */}
      {!activeType && (
        <div className="grid grid-cols-2 md:grid-cols-4 gap-3">
          {allowedTypes.includes('audio') && (
            <button
              onClick={() => startRecording('audio')}
              disabled={disabled}
              className="flex flex-col items-center p-4 border border-gray-300 rounded-lg hover:bg-gray-50 disabled:opacity-50 disabled:cursor-not-allowed"
            >
              <svg className="w-8 h-8 text-blue-600 mb-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
              </svg>
              <span className="text-sm font-medium">Audio</span>
            </button>
          )}

          {allowedTypes.includes('video') && (
            <button
              onClick={() => startRecording('video')}
              disabled={disabled}
              className="flex flex-col items-center p-4 border border-gray-300 rounded-lg hover:bg-gray-50 disabled:opacity-50 disabled:cursor-not-allowed"
            >
              <svg className="w-8 h-8 text-green-600 mb-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z" />
              </svg>
              <span className="text-sm font-medium">Video</span>
            </button>
          )}

          {allowedTypes.includes('image') && (
            <button
              onClick={captureImage}
              disabled={disabled}
              className="flex flex-col items-center p-4 border border-gray-300 rounded-lg hover:bg-gray-50 disabled:opacity-50 disabled:cursor-not-allowed"
            >
              <svg className="w-8 h-8 text-purple-600 mb-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M3 9a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 0110.07 4h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0018.07 7H19a2 2 0 012 2v9a2 2 0 01-2 2H5a2 2 0 01-2-2V9z" />
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M15 13a3 3 0 11-6 0 3 3 0 016 0z" />
              </svg>
              <span className="text-sm font-medium">Photo</span>
            </button>
          )}

          {allowedTypes.includes('file') && (
            <button
              onClick={() => fileInputRef.current?.click()}
              disabled={disabled}
              className="flex flex-col items-center p-4 border border-gray-300 rounded-lg hover:bg-gray-50 disabled:opacity-50 disabled:cursor-not-allowed"
            >
              <svg className="w-8 h-8 text-orange-600 mb-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12" />
              </svg>
              <span className="text-sm font-medium">File</span>
            </button>
          )}
        </div>
      )}

      {/* Device Selection */}
      {(activeType === 'audio' || activeType === 'video' || activeType === 'image') && recordingState.isRecording && (
        <div className="bg-gray-50 rounded-lg p-4">
          <h4 className="font-medium text-gray-900 mb-3">Device Settings</h4>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-1">Microphone</label>
              <select
                value={selectedMicrophone}
                onChange={(e) => setSelectedMicrophone(e.target.value)}
                className="w-full border border-gray-300 rounded-lg px-3 py-2 text-sm"
              >
                {availableDevices
                  .filter(device => device.kind === 'audioinput')
                  .map(device => (
                    <option key={device.deviceId} value={device.deviceId}>
                      {device.label || `Microphone ${device.deviceId.slice(0, 8)}`}
                    </option>
                  ))}
              </select>
            </div>

            {(activeType === 'video' || activeType === 'image') && (
              <div>
                <label className="block text-sm font-medium text-gray-700 mb-1">Camera</label>
                <select
                  value={selectedCamera}
                  onChange={(e) => setSelectedCamera(e.target.value)}
                  className="w-full border border-gray-300 rounded-lg px-3 py-2 text-sm"
                >
                  {availableDevices
                    .filter(device => device.kind === 'videoinput')
                    .map(device => (
                      <option key={device.deviceId} value={device.deviceId}>
                        {device.label || `Camera ${device.deviceId.slice(0, 8)}`}
                      </option>
                    ))}
                </select>
              </div>
            )}
          </div>
        </div>
      )}

      {/* Recording Interface */}
      {activeType && (activeType === 'audio' || activeType === 'video') && (
        <div className="bg-white border border-gray-200 rounded-lg p-6">
          {/* Video Preview */}
          {activeType === 'video' && (
            <div className="mb-4">
              <video
                ref={videoRef}
                className="w-full max-w-md mx-auto rounded-lg bg-black"
                muted
                playsInline
              />
            </div>
          )}

          {/* Recording Controls */}
          <div className="text-center space-y-4">
            <div className="text-2xl font-mono text-gray-900">
              {formatTime(recordingState.currentTime)}
            </div>

            {recordingState.currentTime >= maxDuration && (
              <div className="text-red-600 text-sm">
                Maximum recording duration reached
              </div>
            )}

            <div className="flex justify-center space-x-3">
              {!recordingState.isRecording ? (
                <button
                  onClick={() => startRecording(activeType as 'audio' | 'video')}
                  disabled={disabled}
                  className="px-6 py-3 bg-red-600 text-white rounded-full hover:bg-red-700 disabled:opacity-50 flex items-center space-x-2"
                >
                  <div className="w-4 h-4 bg-white rounded-full"></div>
                  <span>Record</span>
                </button>
              ) : (
                <>
                  <button
                    onClick={pauseRecording}
                    className="px-4 py-2 bg-yellow-600 text-white rounded-lg hover:bg-yellow-700"
                  >
                    {recordingState.isPaused ? 'Resume' : 'Pause'}
                  </button>
                  <button
                    onClick={stopRecording}
                    className="px-4 py-2 bg-gray-600 text-white rounded-lg hover:bg-gray-700"
                  >
                    Stop
                  </button>
                </>
              )}

              <button
                onClick={() => {
                  cleanup();
                  setActiveType(null);
                  setRecordingState({ isRecording: false, isPaused: false, duration: 0, currentTime: 0 });
                }}
                className="px-4 py-2 border border-gray-300 text-gray-700 rounded-lg hover:bg-gray-50"
              >
                Cancel
              </button>
            </div>
          </div>
        </div>
      )}

      {/* Image Capture Interface */}
      {activeType === 'image' && (
        <div className="bg-white border border-gray-200 rounded-lg p-6">
          <div className="text-center space-y-4">
            <video
              ref={videoRef}
              className="w-full max-w-md mx-auto rounded-lg bg-black"
              muted
              playsInline
            />

            <div className="flex justify-center space-x-3">
              <button
                onClick={captureFromVideo}
                className="px-6 py-3 bg-blue-600 text-white rounded-lg hover:bg-blue-700 flex items-center space-x-2"
              >
                <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M3 9a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 0110.07 4h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0018.07 7H19a2 2 0 012 2v9a2 2 0 01-2 2H5a2 2 0 01-2-2V9z" />
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M15 13a3 3 0 11-6 0 3 3 0 016 0z" />
                </svg>
                <span>Capture</span>
              </button>

              <button
                onClick={() => {
                  cleanup();
                  setActiveType(null);
                }}
                className="px-4 py-2 border border-gray-300 text-gray-700 rounded-lg hover:bg-gray-50"
              >
                Cancel
              </button>
            </div>
          </div>
        </div>
      )}

      {/* File Upload */}
      <input
        ref={fileInputRef}
        type="file"
        onChange={handleFileUpload}
        className="hidden"
        accept="*/*"
      />

      {/* Recorded Content Preview */}
      {recordedBlob && (
        <div className="bg-white border border-green-200 rounded-lg p-6">
          <div className="flex items-center justify-between mb-4">
            <h4 className="font-medium text-gray-900">Recorded Response</h4>
            <span className="text-sm text-gray-500">
              {formatFileSize(recordedBlob.size)}
            </span>
          </div>

          {activeType === 'audio' && (
            <div className="space-y-3">
              <audio ref={audioRef} controls className="w-full" />
              <div className="flex justify-center space-x-3">
                <button
                  onClick={playRecording}
                  disabled={isPlaying}
                  className="px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50"
                >
                  {isPlaying ? 'Playing...' : 'Play'}
                </button>
                <button
                  onClick={deleteRecording}
                  className="px-4 py-2 bg-red-600 text-white rounded-lg hover:bg-red-700"
                >
                  Delete
                </button>
              </div>
            </div>
          )}

          {activeType === 'video' && (
            <div className="space-y-3">
              <video ref={videoRef} controls className="w-full max-w-md mx-auto rounded-lg" />
              <div className="flex justify-center space-x-3">
                <button
                  onClick={playRecording}
                  disabled={isPlaying}
                  className="px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50"
                >
                  {isPlaying ? 'Playing...' : 'Play'}
                </button>
                <button
                  onClick={deleteRecording}
                  className="px-4 py-2 bg-red-600 text-white rounded-lg hover:bg-red-700"
                >
                  Delete
                </button>
              </div>
            </div>
          )}

          {activeType === 'image' && (
            <div className="space-y-3">
              <img
                src={URL.createObjectURL(recordedBlob)}
                alt="Captured response"
                className="w-full max-w-md mx-auto rounded-lg"
              />
              <div className="flex justify-center space-x-3">
                <button
                  onClick={deleteRecording}
                  className="px-4 py-2 bg-red-600 text-white rounded-lg hover:bg-red-700"
                >
                  Delete
                </button>
              </div>
            </div>
          )}

          {activeType === 'file' && recordedBlob instanceof File && (
            <div className="space-y-3">
              <div className="flex items-center space-x-3 p-3 bg-gray-50 rounded-lg">
                <svg className="w-8 h-8 text-gray-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                </svg>
                <div className="flex-1">
                  <div className="font-medium text-gray-900">{recordedBlob.name}</div>
                  <div className="text-sm text-gray-500">
                    {recordedBlob.type} • {formatFileSize(recordedBlob.size)}
                  </div>
                </div>
              </div>
              <div className="flex justify-center">
                <button
                  onClick={deleteRecording}
                  className="px-4 py-2 bg-red-600 text-white rounded-lg hover:bg-red-700"
                >
                  Delete
                </button>
              </div>
            </div>
          )}
        </div>
      )}

      {/* Error Display */}
      {error && (
        <div className="bg-red-50 border border-red-200 rounded-lg p-4">
          <div className="flex items-center space-x-2">
            <svg className="w-5 h-5 text-red-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 8v4m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
            </svg>
            <span className="text-red-800">{error}</span>
          </div>
        </div>
      )}

      {/* Hidden elements */}
      <canvas ref={canvasRef} className="hidden" />
    </div>
  );
};

export default MultimediaResponseRecorder;